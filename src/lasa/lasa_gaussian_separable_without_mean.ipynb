{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from functools import wraps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import randn, rand\n",
    "import numdifftools as nd\n",
    "import picos as pc\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime(func):\n",
    "    @wraps(func)\n",
    "    def runtime_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(\"\\n\", f'Function {func.__name__} took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return runtime_wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_dataset = 'Angle'\n",
    "#name_of_dataset = 'Sshape'\n",
    "\n",
    "dataset = loadmat(\"Dataset/\" + name_of_dataset + '.mat')\n",
    "# Unpack the trajectories and place into x and y used in learning step\n",
    "num_of_demos = dataset['demos'].shape[1]\n",
    "size_of_state = dataset['demos'][0, 0][0, 0][0].shape[0]\n",
    "dim_of_function = size_of_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_train_datasets = 4\n",
    "x_cell = None \n",
    "y_cell = None\n",
    "init_position_of_demos = np.zeros((size_of_state, num_of_train_datasets))\n",
    "# Concatenating the dataseries of position and velocities\n",
    "for i in range(0, num_of_train_datasets):\n",
    "    demo_struct = dataset['demos'][0,i][0,0]\n",
    "    position_dataseries = dataset['demos'][0,i][0,0][0]\n",
    "    velocity_dataseries = dataset['demos'][0,i][0,0][2] # is at position 3 in .mat file\n",
    "    init_position_of_demos[:,i] = position_dataseries[:,0]\n",
    "    # create x_cell if not existing\n",
    "    if x_cell is None : \n",
    "        x_cell = position_dataseries\n",
    "    else : \n",
    "        # Example: two arrays of (2,1000) (2,1000) -> get 1 array with (2,2000)\n",
    "        x_cell = np.concatenate((x_cell, position_dataseries), axis = 1)\n",
    "    if y_cell is None : \n",
    "        y_cell = velocity_dataseries\n",
    "    else : \n",
    "        y_cell = np.concatenate((y_cell, velocity_dataseries), axis = 1)\n",
    "\n",
    "x_train = x_cell\n",
    "y_train = y_cell\n",
    "\n",
    "num_of_points = x_train.shape[1]\n",
    "\n",
    "# Get time info for simulating the learnt system later\n",
    "time_step = dataset['dt'][0,0]\n",
    "\n",
    "len_of_dataseries = dataset['demos'][0, 0][0,0][0].shape[1]\n",
    "\n",
    "concatenate = np.concatenate((np.array([[0]]), time_step * np.ones((1, len_of_dataseries - 1))),axis=1)\n",
    "time_series = np.cumsum(concatenate)\n",
    "num_of_timesteps = len_of_dataseries\n",
    "\n",
    "# Intial starting point for the simulated trajectory using learnt model\n",
    "init_condition = init_position_of_demos.mean(axis = 1) # computes the mean across each columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot dataset the four training data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": \"Times New Roman\",\n",
    "})\n",
    "\n",
    "fig_dataset = plt.figure(1)\n",
    "plt.title('The 4 demo sets used for training - ' + name_of_dataset, fontsize=14)\n",
    "plt.plot(x_train[0, :], x_train[1, :], '.')\n",
    "plt.xlabel('x1', fontsize=14)\n",
    "plt.ylabel('x2', fontsize=14)\n",
    "fig_dataset.show()\n",
    "#plt.savefig(r\"lasa_figures/\"+name_of_dataset+\"_lasa_trajectory_4training_demos.eps\", format=\"eps\")\n",
    "axes = plt.gca()  # gca = get current axes, from my last plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define vector-field and axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lower and upper bound for plotting from dataset figure\n",
    "lower_bound_x1 = axes.get_xlim()[0]\n",
    "upper_bound_x1 = axes.get_xlim()[1]\n",
    "lower_bound_x2 = axes.get_ylim()[0]\n",
    "upper_bound_x2 = axes.get_ylim()[1]\n",
    "\n",
    "num_of_points_for_plot = 25\n",
    "\n",
    "x1 = np.linspace(lower_bound_x1, upper_bound_x1, num_of_points_for_plot)\n",
    "x2 = np.linspace(lower_bound_x2, upper_bound_x2, num_of_points_for_plot)\n",
    "\n",
    "# Base point or starting point for each vector of the vector field\n",
    "[X1, X2] = np.meshgrid(x1, x2)\n",
    "\n",
    "# Calculate df/dt for each point\n",
    "t = 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector-valued RFF for Gaussian Separable Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(x, w, b):\n",
    "    return np.sqrt(2) * np.cos(w.T@x + b)\n",
    "\n",
    "\n",
    "def psi_vector(x, w, b, d):\n",
    "    psi_vector = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        x = x.reshape((-1,))\n",
    "        psi_vector[i] = psi(x, w[:, i], b[:, i])\n",
    "    return np.array(psi_vector)\n",
    "\n",
    "\n",
    "def capital_psi(x, w, b, d, dim):\n",
    "    psi = psi_vector(x, w, b, d)\n",
    "    return np.kron(psi, np.eye(dim))\n",
    "\n",
    "\n",
    "def phi(x, w, b, N, d, dim):\n",
    "    phi = np.zeros((dim*N, dim*d))\n",
    "    for i in range(0, N):\n",
    "        psi = capital_psi(x[:, i], w, b, d, dim)\n",
    "        phi[dim*i] = psi[0]\n",
    "        phi[dim*i+1] = psi[1]\n",
    "    return phi\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding alpha without contraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@runtime\n",
    "def alpha_approx(x, y, w, b, dim, d, lam, N):\n",
    "    phi_ = phi(x, w, b, N, d, dim)\n",
    "    alpha_inv_part = np.linalg.inv(phi_.T @ phi_ + lam*np.eye(dim*d))\n",
    "    y_reshaped = np.array(np.ravel([y[0], y[1]], 'F'))\n",
    "    alpha = alpha_inv_part @ (phi_.T @ y_reshaped)\n",
    "    return alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "lambda_ = 0.1\n",
    "num_of_constraint_points = 250\n",
    "num_of_samples = 100 \n",
    "\n",
    "if name_of_dataset == 'Sshape':\n",
    "    num_of_samples = 200\n",
    "\n",
    "#w = randn(size_of_state, num_of_samples)/sigma\n",
    "#b = rand(1, num_of_samples)*2*np.pi\n",
    "\n",
    "w = np.load('RFF_parameters/w_'+name_of_dataset+'_no_mean.npy') \n",
    "b = np.load('RFF_parameters/b_'+name_of_dataset+'_no_mean.npy')\n",
    "\n",
    "mu = 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Fourier Features & Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_rff = alpha_approx(x_train, y_train, w, b, dim_of_function, num_of_samples, lambda_, num_of_points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create callable function for learnt dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnt_model(t, x):\n",
    "    func = capital_psi(x, w, b, num_of_samples, dim_of_function) @ alpha_rff\n",
    "    return func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve differential equation using learnt model with solver_ivp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timespan = np.array([time_series[0],time_series[-1]])\n",
    "t_series = np.linspace(time_series[0],time_series[-1], 1000)\n",
    "data_series = solve_ivp(learnt_model, timespan, init_condition, t_eval = t_series).y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot simulated trajectory and streamslices for learnt model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_learnt = np.zeros(X1.shape)\n",
    "v_learnt = np.zeros(X1.shape)\n",
    "\n",
    "# for loop to get the velocity at each point witht the learnt model\n",
    "for (i, j), value in np.ndenumerate(X1):\n",
    "    # get velocities at each point with the learnt model\n",
    "    #Y_prime = learnt_model_with_constraint(t, np.array([value, X2[i, j]]))\n",
    "    Y_prime = learnt_model(t, np.array([value, X2[i, j]]))\n",
    "    u_learnt[i, j] = Y_prime[0]\n",
    "    v_learnt[i, j] = Y_prime[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined solution and vector field for learnt model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_learntmodel = plt.figure(1)\n",
    "plt.title('Gaussian Separable without constraints', fontsize=14)\n",
    "plt.plot(data_series[0, :], data_series[1, :], '.', linewidth=0.1)\n",
    "plt.streamplot(X1, X2, u_learnt, v_learnt, density=1.1, color='gray')\n",
    "plt.xlabel('x1', fontsize=14)\n",
    "plt.ylabel('x2', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=14)\n",
    "plt.tick_params(axis='y', labelsize=14)\n",
    "plt.legend(['Trajectory', 'Streamlines'], loc=\"upper left\", frameon=True, prop={'size': 14})\n",
    "fig_learntmodel.show()\n",
    "#plt.savefig(r\"lasa_figures/\"+name_of_dataset+\"_lasa_gauss_rff_without_constraints_no_mean.eps\", format=\"eps\", transparent=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducing accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_test_datasets = num_of_demos - num_of_train_datasets\n",
    "trajectory_error = np.zeros(num_of_test_datasets)\n",
    "\n",
    "for i in range(num_of_test_datasets):\n",
    "    demo_pos = num_of_train_datasets + i\n",
    "    actual_trajectory = dataset['demos'][0, demo_pos][0, 0][0]\n",
    "    actual_time = dataset['demos'][0, demo_pos][0, 0][1]\n",
    "    timespan = np.array([actual_time[:, 0], actual_time[:, -1]])\n",
    "    initial_condition = actual_trajectory[:, 0]\n",
    "    simulated_trajectory = solve_ivp(learnt_model, timespan, initial_condition, t_eval=actual_time[0]).y\n",
    "    error = np.mean(np.linalg.norm(actual_trajectory - simulated_trajectory, ord=2, axis=0) / actual_time[:, -1])\n",
    "    trajectory_error[i] = error\n",
    "    print(trajectory_error)\n",
    "    demo_number = demo_pos+1\n",
    "    fig_learntmodel = plt.figure(i+num_of_train_datasets)\n",
    "    plt.title('Actual trajectory & Simulated trajectory for Demo ' + str(demo_number), fontsize=16)\n",
    "    plt.plot(actual_trajectory[0, :], actual_trajectory[1, :], '.', linewidth=0.1, color='r')\n",
    "    plt.plot(simulated_trajectory[0, :], simulated_trajectory[1, :], '.', linewidth=0.1)\n",
    "    plt.streamplot(X1, X2, u_learnt, v_learnt, density=1.1, color='gray')\n",
    "    plt.xlabel('x1', fontsize=16)\n",
    "    plt.ylabel('x2', fontsize=16)\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    fig_learntmodel.show()\n",
    "    #plt.savefig(r\"lasa_figures/\"+name_of_dataset+\"_lasa_gauss_without_constraints_accuracy_demo\" +str(demo_number)+\"_no_mean.eps\", format=\"eps\", transparent=True)\n",
    "\n",
    "trajectory_mean_error = np.mean(trajectory_error)\n",
    "print(np.mean(trajectory_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('RFF_parameters/w_'+name_of_dataset+'_no_mean', w)\n",
    "#np.save('RFF_parameters/b_'+name_of_dataset+'_no_mean', b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "364ce0aa04b075b5f9a8a87d4ba65b1dbc176d267b37027aa80213cb40fae0fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
