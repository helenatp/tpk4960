{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian separable models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from functools import wraps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import randn, rand\n",
    "import numdifftools as nd\n",
    "import picos as pc\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime(func):\n",
    "    @wraps(func)\n",
    "    def runtime_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(\"\\n\", f'Function {func.__name__} took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return runtime_wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_dataset = 'Angle'    # To run Angle-shape\n",
    "#name_of_dataset = 'Sshape'  # To run S-shape\n",
    "\n",
    "# Unpack the trajectories and place into x and y used in learning step\n",
    "dataset = loadmat(\"Dataset/\" + name_of_dataset + '.mat')\n",
    "num_of_demos = dataset['demos'].shape[1]\n",
    "size_of_state = dataset['demos'][0, 0][0,0][0].shape[0]\n",
    "dim_of_function = size_of_state "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of training demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_train_datasets = 4\n",
    "num_of_points = len(dataset['demos'][0,0][0,0][0][0])\n",
    "\n",
    "pos_cell_1 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "pos_cell_2 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "vel_cell_1 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "vel_cell_2 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "\n",
    "# Concatenating the dataseries of position and velocities\n",
    "for i in range(0, num_of_train_datasets):\n",
    "    demo_struct = dataset['demos'][0,i][0,0]\n",
    "\n",
    "    position_dataseries = dataset['demos'][0,i][0,0][0]\n",
    "    velocity_dataseries = dataset['demos'][0,i][0,0][2]\n",
    "\n",
    "    pos_cell_1[:, i] = position_dataseries[0]\n",
    "    pos_cell_2[:, i] = position_dataseries[1]\n",
    "    vel_cell_1[:, i] = velocity_dataseries[0]\n",
    "    vel_cell_2[:, i] = velocity_dataseries[1]\n",
    "\n",
    "x_train_1 = pos_cell_1.mean(axis=1)\n",
    "x_train_2 = pos_cell_2.mean(axis=1)\n",
    "y_train_1 = vel_cell_1.mean(axis=1)\n",
    "y_train_2 = vel_cell_2.mean(axis=1)\n",
    "\n",
    "# Defines the position and velocity measurements\n",
    "x_train = np.array([x_train_1, x_train_2])\n",
    "y_train = np.array([y_train_1, y_train_2])\n",
    "\n",
    "# Get time info for simulating the learnt system later\n",
    "time_step = dataset['dt'][0,0]\n",
    "\n",
    "len_of_dataseries = dataset['demos'][0, 0][0,0][0].shape[1] \n",
    "\n",
    "concatenate = np.concatenate((np.array([[0]]), time_step * np.ones((1, len_of_dataseries - 1))),axis=1)\n",
    "time_series = np.cumsum(concatenate)\n",
    "num_of_timesteps = len_of_dataseries\n",
    "num_of_test_datasets = num_of_demos - num_of_train_datasets\n",
    "\n",
    "# Intial starting point for the simulated trajectory using learnt model\n",
    "init_condition = x_train[:, 0]\n",
    "\n",
    "timespan = np.array([time_series[0],time_series[-1]])\n",
    "t_series = np.linspace(time_series[0],time_series[-1], 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": \"Times New Roman\",\n",
    "})\n",
    "\n",
    "fig_dataset = plt.figure(1)\n",
    "plt.title('Trajectory used in regression problem - ' + name_of_dataset, fontsize=14)\n",
    "plt.plot(x_train[0,:], x_train[1,:], '.')\n",
    "plt.xlabel('x1', fontsize =12)\n",
    "plt.ylabel('x2', fontsize=12)\n",
    "fig_dataset.show()\n",
    "axes = plt.gca()  # Get current axes from the last plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define vector-field and axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lower and upper bound for plotting from dataset figure\n",
    "lower_bound_x1 = axes.get_xlim()[0]\n",
    "upper_bound_x1 = axes.get_xlim()[1]\n",
    "lower_bound_x2 = axes.get_ylim()[0]\n",
    "upper_bound_x2 = axes.get_ylim()[1]\n",
    "\n",
    "num_of_points_for_plot = 25\n",
    "\n",
    "x1 = np.linspace(lower_bound_x1-8, upper_bound_x1+8, num_of_points_for_plot)\n",
    "x2 = np.linspace(lower_bound_x2-3, upper_bound_x2+3, num_of_points_for_plot)\n",
    "\n",
    "# Base point or starting point for each vector of the vector field\n",
    "[X1, X2] = np.meshgrid(x1, x2)\n",
    "\n",
    "# Calculate df/dt for each point\n",
    "t = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression problems with Gaussian separable feature map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(x, w, b):\n",
    "    return np.sqrt(2) * np.cos(w.T@x + b)\n",
    "\n",
    "def psi_vector(x, w, b, d):\n",
    "    psi_vector = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        x = x.reshape((-1,))\n",
    "        psi_vector[i] = psi(x, w[:, i], b[:,i])\n",
    "    return np.array(psi_vector)\n",
    "\n",
    "def capital_psi(x, w, b, d, dim):\n",
    "    psi = psi_vector(x, w, b, d)\n",
    "    return np.kron(psi, np.eye(dim))\n",
    "\n",
    "def phi(x, w, b, N, d, dim):\n",
    "    phi = np.zeros((dim*N, dim*d))\n",
    "    for i in range(0, N):\n",
    "        psi = capital_psi(x[:,i], w, b, d, dim)\n",
    "        phi[dim*i] = psi[0]\n",
    "        phi[dim*i+1] = psi[1]\n",
    "    return phi\n",
    "\n",
    "def gradient_of_psi(x, w, b):\n",
    "    return np.sqrt(2) * (-np.sin(w.T@x + b)) * w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "lambda_ = 0.1\n",
    "num_of_constraint_points = 250\n",
    "num_of_samples = 100\n",
    "mu = 0.0\n",
    "\n",
    "if name_of_dataset == 'Sshape':\n",
    "    num_of_samples = 200\n",
    "\n",
    "# Generate parameters for feature map\n",
    "#w = randn(size_of_state, num_of_samples)/sigma\n",
    "#b = rand(1,num_of_samples)*2*np.pi\n",
    "\n",
    "# Load the saved parameters for feature map\n",
    "w = np.load('RFF_parameters/w_'+name_of_dataset+'_rff.npy')\n",
    "b = np.load('RFF_parameters/b_'+name_of_dataset+'_rff.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without contraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha without contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@runtime\n",
    "def alpha_approx(x, y, w, b, dim, d, lam, N):\n",
    "    phi_ = phi(x, w, b, N, d, dim)\n",
    "    alpha_inv_part = np.linalg.inv(phi_.T @ phi_ + lam*np.eye(dim*d))\n",
    "    y_reshaped = np.array(np.ravel([y[0], y[1]], 'F'))\n",
    "    alpha = alpha_inv_part @ (phi_.T @ y_reshaped)\n",
    "    return alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_rff = alpha_approx(x_train, y_train, w, b, dim_of_function, num_of_samples, lambda_, num_of_points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnt_model(t, x):\n",
    "    func = capital_psi(x, w, b, num_of_samples, dim_of_function) @ alpha_rff\n",
    "    return func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series = solve_ivp(learnt_model, timespan, init_condition, t_eval = t_series).y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot vector field for learnt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_learnt = np.zeros(X1.shape)\n",
    "v_learnt = np.zeros(X1.shape)\n",
    "\n",
    "# for loop to get the velocity at each point witht the learnt model\n",
    "for (i,j), value in np.ndenumerate(X1):\n",
    "    # get velocities at each point with the learnt model\n",
    "    Y_prime = learnt_model(t, np.array([value, X2[i, j]]))\n",
    "    u_learnt[i,j] = Y_prime[0]\n",
    "    v_learnt[i,j] = Y_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_learntmodel = plt.figure(1)\n",
    "plt.title('Gaussian Separable without constraints', fontsize=14)\n",
    "plt.plot(data_series[0, :], data_series[1, :], '.', linewidth=0.1)\n",
    "plt.streamplot(X1, X2, u_learnt, v_learnt, density = 1.1, color ='gray')\n",
    "plt.xlabel('x1', fontsize=14)\n",
    "plt.ylabel('x2', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=14)\n",
    "plt.tick_params(axis='y', labelsize=14)\n",
    "plt.legend(['Trajectory', 'Streamlines'], loc = \"upper left\" , frameon = True , prop ={'size': 14 } )\n",
    "fig_learntmodel.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_error = np.zeros(num_of_test_datasets)\n",
    "\n",
    "for i in range(num_of_test_datasets):\n",
    "    demo_pos = num_of_train_datasets + i\n",
    "    actual_trajectory = dataset['demos'][0, demo_pos][0, 0][0]\n",
    "    actual_time = dataset['demos'][0, demo_pos][0, 0][1]\n",
    "    timespan = np.array([actual_time[:, 0], actual_time[:, -1]])\n",
    "    initial_condition = actual_trajectory[:, 0]\n",
    "    simulated_trajectory = solve_ivp(learnt_model, timespan, initial_condition, t_eval = actual_time[0]).y\n",
    "    error = np.mean(np.linalg.norm(actual_trajectory - simulated_trajectory, ord=2, axis=0) / actual_time[:, -1])\n",
    "    trajectory_error[i] = error\n",
    "    demo_number = demo_pos+1\n",
    "    fig_learntmodel = plt.figure(i+num_of_train_datasets)\n",
    "    plt.title('Actual trajectory & Simulated trajectory for Demo ' + str(demo_number), fontsize=16)\n",
    "    plt.plot(actual_trajectory[0, :], actual_trajectory[1, :], '.', linewidth=0.1, color = 'r')\n",
    "    plt.plot(simulated_trajectory[0, :], simulated_trajectory[1, :], '.', linewidth=0.1)\n",
    "    plt.streamplot(X1, X2, u_learnt, v_learnt, density = 1.1, color ='gray')\n",
    "    plt.xlabel('x1', fontsize=18)\n",
    "    plt.ylabel('x2', fontsize=18)\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    fig_learntmodel.show()\n",
    "\n",
    "print('The trajectory error: ', trajectory_error)\n",
    "print('The mean trajectory error (MTE): ', np.mean(trajectory_error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with contraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha with contraction constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@runtime\n",
    "def alpha_approx_with_constraint(x, y, w, b, dim, d, lam, N, mu, constraint_points):\n",
    "    phi_ = phi(x, w, b, N, d, dim)\n",
    "    mu = mu * np.eye(dim)\n",
    "    problem = pc.Problem()\n",
    "    phi_param = pc.Constant('phi_', phi_)\n",
    "    lam_param = pc.Constant('lam', lam)\n",
    "    dim_param = pc.Constant('dim',dim)\n",
    "    d_param = pc.Constant('d', d)\n",
    "    mu_param = pc.Constant('mu', mu)\n",
    "    constraint_points_param = pc.Constant('constraint_points', constraint_points)\n",
    "    y_reshaped = np.array(np.ravel([y[0], y[1]], 'F'))\n",
    "    y_reshaped_param = pc.Constant('y_reshaped', y_reshaped)\n",
    "    alpha_var = pc.RealVariable('alpha_var', (d_param*dim_param, 1))\n",
    "    # Creating constraints\n",
    "    for i in range(constraint_points_param):\n",
    "        constraint_index = i*np.int64(np.floor(len(x[0])/constraint_points))\n",
    "        x_i = x[:, constraint_index]\n",
    "        gradient = np.zeros(dim)\n",
    "        for j in range(d):\n",
    "            index = 2*j\n",
    "            gradient_of_psi_param = pc.Constant('gradient_of_psi', gradient_of_psi(x_i, w[:, j], b[:, j]))\n",
    "            jacobi = alpha_var[index:index+2] * gradient_of_psi_param.T\n",
    "            gradient = gradient + 0.5 * (jacobi + jacobi.T)\n",
    "        problem.add_constraint(gradient << mu_param)\n",
    "    obj = ((phi_param * alpha_var) - y_reshaped_param).T * ((phi_param * alpha_var) - y_reshaped_param) + lam_param*(alpha_var.T * alpha_var)\n",
    "    problem.set_objective('min', obj)\n",
    "    problem.solve(solver='mosek')\n",
    "    alpha_var = alpha_var.np.reshape((-1,))\n",
    "    return alpha_var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_rff_with_constraint = alpha_approx_with_constraint(x_train, y_train, w, b, dim_of_function, num_of_samples, lambda_, num_of_points, mu, num_of_constraint_points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnt_model_with_constraint(t, x):\n",
    "    func = capital_psi(x, w, b, num_of_samples, dim_of_function) @ alpha_rff_with_constraint\n",
    "    return func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series_contraction = solve_ivp(learnt_model_with_constraint, timespan, init_condition, t_eval = t_series).y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot vector field for learnt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_learnt = np.zeros(X1.shape)\n",
    "v_learnt = np.zeros(X1.shape)\n",
    "\n",
    "# for loop to get the velocity at each point with the learnt model\n",
    "for (i,j), value in np.ndenumerate(X1):\n",
    "    Y_prime = learnt_model_with_constraint(t, np.array([value, X2[i, j]]))\n",
    "    u_learnt[i,j] = Y_prime[0]\n",
    "    v_learnt[i,j] = Y_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_learntmodel_contraction = plt.figure(2)\n",
    "plt.title('Gaussian Separable with contraction', fontsize=14)\n",
    "plt.plot(data_series_contraction[0, :], data_series_contraction[1, :], '.', linewidth=0.1)\n",
    "plt.streamplot(X1, X2, u_learnt, v_learnt, density = 1.1, color ='gray')\n",
    "plt.xlabel('x1', fontsize=14)\n",
    "plt.ylabel('x2', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=14)\n",
    "plt.tick_params(axis='y', labelsize=14)\n",
    "plt.legend(['Trajectory', 'Streamlines'], loc = \"upper left\" , frameon = True , prop ={'size': 14 } )\n",
    "fig_learntmodel_contraction.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproduction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_error = np.zeros(num_of_test_datasets)\n",
    "\n",
    "for i in range(num_of_test_datasets):\n",
    "    demo_pos = num_of_train_datasets + i\n",
    "    actual_trajectory = dataset['demos'][0, demo_pos][0, 0][0]\n",
    "    actual_time = dataset['demos'][0, demo_pos][0, 0][1]\n",
    "    timespan = np.array([actual_time[:, 0], actual_time[:, -1]])\n",
    "    initial_condition = actual_trajectory[:, 0]\n",
    "    simulated_trajectory = solve_ivp(learnt_model_with_constraint, timespan, initial_condition, t_eval = actual_time[0]).y\n",
    "    error = np.mean(np.linalg.norm(actual_trajectory - simulated_trajectory, ord=2, axis=0) / actual_time[:, -1])\n",
    "    trajectory_error[i] = error\n",
    "    demo_number = demo_pos+1\n",
    "    fig_learntmodel = plt.figure(i+num_of_train_datasets)\n",
    "    plt.title('Actual trajectory & Simulated trajectory for Demo ' + str(demo_number), fontsize=16)\n",
    "    plt.plot(actual_trajectory[0, :], actual_trajectory[1, :], '.', linewidth=0.1, color = 'r')\n",
    "    plt.plot(simulated_trajectory[0, :], simulated_trajectory[1, :], '.', linewidth=0.1)\n",
    "    plt.streamplot(X1, X2, u_learnt, v_learnt, density = 1.1, color ='gray')\n",
    "    plt.xlabel('x1', fontsize=18)\n",
    "    plt.ylabel('x2', fontsize=18)\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    fig_learntmodel.show()\n",
    "\n",
    "print('The trajectory error: ', trajectory_error)\n",
    "print('The mean trajectory error (MTE): ', np.mean(trajectory_error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save satisfactory feature map parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('RFF_parameters/w_'+name_of_dataset+'_rff', w)\n",
    "#np.save('RFF_parameters/b_'+name_of_dataset+'_rff', b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "364ce0aa04b075b5f9a8a87d4ba65b1dbc176d267b37027aa80213cb40fae0fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
