{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with curl-free feature map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from functools import wraps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import randn, rand\n",
    "import numdifftools as nd\n",
    "import picos as pc\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime(func):\n",
    "    @wraps(func)\n",
    "    def runtime_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(\"\\n\", f'Function {func.__name__} took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return runtime_wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_dataset = 'Angle'   # To run Angle-shape\n",
    "#name_of_dataset = 'Sshape' # To run S-shape\n",
    "\n",
    "dataset = loadmat(\"Dataset/\" + name_of_dataset + '.mat')\n",
    "\n",
    "# Unpack the trajectories and place into x and y used in learning step\n",
    "num_of_demos = dataset['demos'].shape[1]\n",
    "size_of_state = dataset['demos'][0, 0][0,0][0].shape[0]\n",
    "dim_of_function = size_of_state "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of training demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_train_datasets = 4\n",
    "num_of_points = len(dataset['demos'][0,0][0,0][0][0])\n",
    "\n",
    "pos_cell_1 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "pos_cell_2 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "vel_cell_1 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "vel_cell_2 = np.zeros((num_of_points, num_of_train_datasets))\n",
    "\n",
    "# Concatenating the dataseries of position and velocities\n",
    "for i in range(0, num_of_train_datasets):\n",
    "    demo_struct = dataset['demos'][0,i][0,0]\n",
    "\n",
    "    position_dataseries = dataset['demos'][0,i][0,0][0]\n",
    "    velocity_dataseries = dataset['demos'][0,i][0,0][2]\n",
    "\n",
    "    pos_cell_1[:, i] = position_dataseries[0]\n",
    "    pos_cell_2[:, i] = position_dataseries[1]\n",
    "    vel_cell_1[:, i] = velocity_dataseries[0]\n",
    "    vel_cell_2[:, i] = velocity_dataseries[1]\n",
    "\n",
    "x_train_1 = pos_cell_1.mean(axis=1)\n",
    "x_train_2 = pos_cell_2.mean(axis=1)\n",
    "y_train_1 = vel_cell_1.mean(axis=1)\n",
    "y_train_2 = vel_cell_2.mean(axis=1)\n",
    "\n",
    "# Defines the position and velocity measurements\n",
    "x_train = np.array([x_train_1, x_train_2])\n",
    "y_train = np.array([y_train_1, y_train_2])\n",
    "\n",
    "# Get time info for simulating the learnt system later\n",
    "time_step = dataset['dt'][0,0]\n",
    "\n",
    "len_of_dataseries = dataset['demos'][0, 0][0,0][0].shape[1] \n",
    "\n",
    "concatenate = np.concatenate((np.array([[0]]), time_step * np.ones((1, len_of_dataseries - 1))),axis=1)\n",
    "time_series = np.cumsum(concatenate)\n",
    "num_of_timesteps = len_of_dataseries\n",
    "num_of_test_datasets = num_of_demos - num_of_train_datasets\n",
    "\n",
    "# Intial starting point for the simulated trajectory using learnt model\n",
    "init_condition = x_train[:, 0]\n",
    "\n",
    "timespan = np.array([time_series[0],time_series[-1]])\n",
    "t_series = np.linspace(time_series[0],time_series[-1], 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": \"Times New Roman\",\n",
    "})\n",
    "\n",
    "fig_dataset = plt.figure(1)\n",
    "plt.title('Trajectory used in regression problem - ' + name_of_dataset, fontsize=14)\n",
    "plt.plot(x_train[0,:], x_train[1,:], '.')\n",
    "plt.xlabel('x1', fontsize =12)\n",
    "plt.ylabel('x2', fontsize=12)\n",
    "fig_dataset.show()\n",
    "axes = plt.gca()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define vector-field and axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lower and upper bound for plotting from dataset figure\n",
    "lower_bound_x1 = axes.get_xlim()[0]\n",
    "upper_bound_x1 = axes.get_xlim()[1]\n",
    "lower_bound_x2 = axes.get_ylim()[0]\n",
    "upper_bound_x2 = axes.get_ylim()[1]\n",
    "\n",
    "num_of_points_for_plot = 25\n",
    "\n",
    "x1 = np.linspace(lower_bound_x1-4, upper_bound_x1+6, num_of_points_for_plot)\n",
    "x2 = np.linspace(lower_bound_x2-4, upper_bound_x2+6, num_of_points_for_plot)\n",
    "\n",
    "# Base point or starting point for each vector of the vector field\n",
    "[X1, X2] = np.meshgrid(x1, x2)\n",
    "\n",
    "t = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curl-free model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "lambda_ = 0.1\n",
    "num_of_constraint_points = 250\n",
    "num_of_samples = 100\n",
    "mu = 0.0\n",
    "\n",
    "if name_of_dataset == 'Sshape':\n",
    "    num_of_samples = 200\n",
    "\n",
    "# Generate parameters for feature map\n",
    "#w = randn(size_of_state, num_of_samples)/sigma\n",
    "#b = rand(1,num_of_samples)*2*np.pi\n",
    "\n",
    "# Load the saved parameters for feature map\n",
    "w = np.load('RFF_parameters/w_'+name_of_dataset+'_cf_with_contraction.npy')\n",
    "b = np.load('RFF_parameters/b_'+name_of_dataset+'_cf_with_contraction.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_curl_free(x, w, b):\n",
    "    return np.sqrt(2) * np.sin(w.T@x+b)*w.T\n",
    "\n",
    "def capital_psi_cf(x, w, b, d, dim):\n",
    "    psi_vector_cf = np.zeros((d, dim))\n",
    "    for i in range(d):\n",
    "        psi_element = psi_curl_free(x, w[:,i], b[:,i])\n",
    "        psi_vector_cf[i] = psi_element\n",
    "    return np.array(psi_vector_cf).T\n",
    "\n",
    "def phi_function_cf(x, w, b, N, d, dim):\n",
    "    phi = np.zeros((dim*N, d))\n",
    "    psi_cf = capital_psi_cf(x, w, b, d, dim)\n",
    "    phi[dim*0] = psi_cf[0]\n",
    "    phi[dim*0+1] = psi_cf[1]\n",
    "    return phi\n",
    "\n",
    "def capital_psi_z_function_cf(x, w, b, d, dim, L):\n",
    "    psi = capital_psi_cf(x, w, b, d, dim)\n",
    "    return L.T @ psi.T\n",
    "\n",
    "def capital_phi_z_function_cf(x, w, b, N, d, dim, L):\n",
    "    phi = np.zeros((dim*N, d))\n",
    "    for i in range(N):\n",
    "        psi = capital_psi_z_function_cf(x[:,i], w, b, d, dim, L)\n",
    "        phi[dim*i] = psi.T[0]\n",
    "        phi[dim*i+1] = psi.T[1]\n",
    "    return phi\n",
    "\n",
    "def capital_phi_function(x, w, b, N, d, dim):\n",
    "    phi = np.zeros((dim*N, d))\n",
    "    for i in range(N):\n",
    "        psi = capital_psi_cf(x[:,i], w, b, d, dim)\n",
    "        phi[dim*i] = psi[0]\n",
    "        phi[dim*i+1] = psi[1]\n",
    "    return phi\n",
    "\n",
    "def psi_jacobi_cf(x, w, b, d, dim, L):\n",
    "    psi_vector_cf = np.zeros((d,dim))\n",
    "    for i in range(d):\n",
    "        psi_vector_cf[i] = np.sin(w[:, i].T@x + b[:, i])*w[:, i].T\n",
    "    psi = np.sqrt(2/d) * psi_vector_cf\n",
    "    psi_L = L.T @ psi\n",
    "    return psi_L.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vanish = x_train[:,-1]\n",
    "num_of_vanish_points = np.size(x_vanish[0])\n",
    "\n",
    "capital_phi_z_cf = phi_function_cf(x_vanish, w, b, num_of_vanish_points, num_of_samples, dim_of_function)\n",
    "capital_phi_z_cf = capital_phi_z_cf.T\n",
    "\n",
    "P_Psi_cf = capital_phi_z_cf @ np.linalg.inv(capital_phi_z_cf.T @ capital_phi_z_cf)@capital_phi_z_cf.T\n",
    "P_Psi_cf = np.eye(P_Psi_cf[0].size) - P_Psi_cf\n",
    "P_Psi_cf = (P_Psi_cf + P_Psi_cf.T) / 2 + (np.eye(P_Psi_cf[0].size)*1e-12) # Ensure P is a Hermitian positive-definite matrix given numerical noise\n",
    "L_cf = np.linalg.cholesky(P_Psi_cf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha with contraction and vanishing point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@runtime\n",
    "def alpha_approx_with_constraint_cf(x, y, w, b, dim, d, lam, N, mu, constraint_points, L):\n",
    "    phi_ = capital_phi_z_function_cf(x, w, b, N, d, dim, L)\n",
    "    mu = mu * np.eye(dim)\n",
    "    problem = pc.Problem()\n",
    "    phi_param = pc.Constant('phi_', phi_)\n",
    "    lam_param = pc.Constant('lam', lam)\n",
    "    d_param = pc.Constant('d', d)\n",
    "    mu_param = pc.Constant('mu', mu)\n",
    "    constraint_points_param = pc.Constant('constraint_points', constraint_points)\n",
    "    y_reshaped = np.array(np.ravel([y[0], y[1]], 'F'))\n",
    "    y_reshaped_param = pc.Constant('y_reshaped', y_reshaped)\n",
    "    alpha_var = pc.RealVariable('alpha_var', (d_param, 1))\n",
    "    jacobi_function = nd.Jacobian(psi_jacobi_cf)\n",
    "\n",
    "    # Create constraints\n",
    "    for i in range(constraint_points_param):\n",
    "        constraint_index = i*np.int64(np.floor(len(x[0])/constraint_points))\n",
    "        x_i = x[:, constraint_index]\n",
    "        gradient = np.zeros(dim)\n",
    "        jacobi_ = jacobi_function(x_i, w, b, d, dim, L)\n",
    "        jacobi_param = pc.Constant('jacobi', [0, 0], (2, 2))\n",
    "        for j in range(len(alpha_var)):\n",
    "            jacobi_param += pc.Constant(jacobi_[:, :, j]) * alpha_var[j]\n",
    "        gradient = gradient + 0.5 * (jacobi_param + jacobi_param.T)\n",
    "        problem.add_constraint(gradient << mu_param)\n",
    "    obj = ((phi_param * alpha_var) - y_reshaped_param).T * ((phi_param * alpha_var) - y_reshaped_param) + lam_param*(alpha_var.T * alpha_var)\n",
    "    problem.set_objective('min', obj)\n",
    "    problem.solve(solver='mosek')\n",
    "    alpha_var = alpha_var.np.reshape((-1,))\n",
    "    return alpha_var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_cf_with_constraints = alpha_approx_with_constraint_cf(x_train, y_train, w, b, dim_of_function, num_of_samples, lambda_, num_of_points, mu, num_of_constraint_points, L_cf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnt_model_cf_with_constraints(t, x):\n",
    "    func = capital_psi_z_function_cf(x, w, b, num_of_samples, dim_of_function, L_cf).T @ alpha_cf_with_constraints\n",
    "    return func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series_cf = solve_ivp(learnt_model_cf_with_constraints, timespan, init_condition, t_eval = t_series).y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot vector field for learnt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_learnt_cf = np.zeros(X1.shape)\n",
    "v_learnt_cf = np.zeros(X1.shape)\n",
    "\n",
    "for (i,j), value in np.ndenumerate(X1):\n",
    "    Y_prime_cf = learnt_model_cf_with_constraints(t, np.array([value, X2[i, j]]))\n",
    "    u_learnt_cf[i,j] = Y_prime_cf[0]\n",
    "    v_learnt_cf[i,j] = Y_prime_cf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_learntmodel_cf_with_constraints = plt.figure(1)\n",
    "plt.title('Curl-Free with constraints and vanishing point', fontsize=14)\n",
    "plt.plot(data_series_cf[0, :], data_series_cf[1, :], '.', linewidth=0.1)\n",
    "plt.streamplot(X1, X2, u_learnt_cf, v_learnt_cf, density = 1.1, color ='gray')\n",
    "plt.xlabel('x1', fontsize=14)\n",
    "plt.ylabel('x2', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=14)\n",
    "plt.tick_params(axis='y', labelsize=14)\n",
    "plt.plot(0, 0, marker='o', markersize = 11, color = 'green')\n",
    "plt.legend(['Trajectory', 'Streamlines'], loc = \"upper left\" , frameon = True , prop ={'size': 14 } )\n",
    "fig_learntmodel_cf_with_constraints.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproduction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_error = np.zeros(num_of_test_datasets)\n",
    "\n",
    "for i in range(num_of_test_datasets):\n",
    "    demo_pos = num_of_train_datasets + i\n",
    "    actual_trajectory = dataset['demos'][0, demo_pos][0, 0][0]\n",
    "    actual_time = dataset['demos'][0, demo_pos][0, 0][1]\n",
    "    timespan = np.array([actual_time[:, 0], actual_time[:, -1]])\n",
    "    initial_condition = actual_trajectory[:, 0]\n",
    "    simulated_trajectory = solve_ivp(learnt_model_cf_with_constraints, timespan, initial_condition, t_eval = actual_time[0]).y\n",
    "    error = np.mean(np.linalg.norm(actual_trajectory - simulated_trajectory, ord=2, axis=0) / actual_time[:, -1])\n",
    "    trajectory_error[i] = error\n",
    "    demo_number = demo_pos+1\n",
    "    fig_learntmodel_cf = plt.figure()\n",
    "    plt.title('Actual trajectory & Simulated trajectory for Demo '+str(demo_pos+1), fontsize=16)\n",
    "    plt.plot(actual_trajectory[0, :], actual_trajectory[1, :], '.', linewidth=0.1, color='red')\n",
    "    plt.plot(simulated_trajectory[0, :], simulated_trajectory[1, :], '.', linewidth=0.1)\n",
    "    plt.streamplot(X1, X2, u_learnt_cf, v_learnt_cf, density = 1.1, color ='gray')\n",
    "    plt.plot(0, 0, marker='o', markersize = 12, color = 'green')\n",
    "    plt.xlabel('x1', fontsize=16)\n",
    "    plt.ylabel('x2', fontsize=16)\n",
    "    plt.tick_params(axis='x', labelsize=16)\n",
    "    plt.tick_params(axis='y', labelsize=16)\n",
    "    fig_learntmodel_cf.show()\n",
    "\n",
    "print('The trajectory error: ',  trajectory_error)\n",
    "\n",
    "trajectory_mean_error = np.mean(trajectory_error)\n",
    "print('The mean trajectory error (MTE): ', np.mean(trajectory_error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save satisfactory feature map parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('RFF_parameters/w_'+name_of_dataset+'_cf_with_contraction', w)\n",
    "#np.save('RFF_parameters/b_'+name_of_dataset+'_cf_with_contraction', b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "364ce0aa04b075b5f9a8a87d4ba65b1dbc176d267b37027aa80213cb40fae0fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
